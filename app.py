import streamlit as st
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

load_dotenv()
st.session_state.API_KEY=os.getenv("GOOGLE_API_KEY")
st.title("Hola")
st.markdown("bienvenido a ğŸ¤–chat")


prompt_template = PromptTemplate(
    input_variables=["history", "user_input"],
    template="Historial de la conversaciÃ³n:\n{history}\n\nUsuario: {user_input}\n\nAsistente:",
)


# with st.chat_message("assistant", avatar="ğŸ¤–"):
#     st.write("Hola, soy un sigma")
# with st.chat_message("user", avatar="ğŸŒ¯"):
#     st.write("Hola")
st.session_state.geminai = ChatGoogleGenerativeAI(model="gemini-1.5-pro", api_key=st.session_state.API_KEY)

def generar_respuesta(mensage):
    st.write(mensage)
    return st.session_state.geminai.invoke(mensage)

if "mensages" not in st.session_state:
    st.session_state.mensages=[
        {"role": "assistant", "avatar": "ğŸ¤–", "content": "hola, soy un sigma"}
    ]

mensage_usuario=st.chat_input("escribe aquÃ­ tu mensage")


for mensage in st.session_state.mensages:
    with st.chat_message(mensage["role"], avatar=(mensage["avatar"])):
        st.write(mensage["content"])

if mensage_usuario is not None:
    st.session_state.mensages.append(
        {"role": "user", "content": mensage_usuario, "avatar": "ğŸŒ¯"}
    )
    for mensage in st.session_state.mensages:
        historial=""
        historial=historial+f" {mensage["role"]}: {mensage["content"]} \n"

    
    prompt=prompt_template.format(
        history=historial,
        user_input=mensage_usuario
    )
    r=generar_respuesta(prompt).content
    with st.chat_message("user", avatar="ğŸŒ¯"):
        st.write(mensage_usuario)
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.write(r)
    st.session_state.mensages.append({"role": "assistant", "avatar": "ğŸ¤–", "content": r})
